##' ---
##' title: "Appendix: `complete_tf_cpc` module"
##' author:
##'   - Marco Garieri
##'   - Alexander Matrunich
##'   - Christian A. Mongeau Ospina
##'   - Bo Werth\
##'
##'     Food and Agriculture Organization of the United Nations
##' date: "`r format(Sys.time(), '%e %B %Y')`"
##' output:
##'    pdf_document
##' ---

##' This document gives a faithful step-by-step sequence of the operations
##' performed in the `complete_tf_cpc` module. For a narrative version of
##' the module's approach, please see its main document.

##+ setup, include=FALSE
knitr::opts_chunk$set(echo = FALSE, eval = FALSE)

startTime = Sys.time()

# Libraries ####
suppressPackageStartupMessages(library(data.table))
library(stringr)
library(magrittr)
library(scales)
library(tidyr, warn.conflicts = FALSE)
library(futile.logger)
suppressPackageStartupMessages(library(dplyr, warn.conflicts = FALSE))
library(faosws)
library(faoswsUtil)
library(faoswsTrade)
library(faoswsFlag)
library(bit64)

# Always source files in R/ (useful for local runs)
sapply(dir("R", full.names = TRUE), source)

##+ check_parameters

# Stop if required parameters were not set
# The out_coef was removed as a parameter given that the
# outlier detection/imputation was disabled.
#stopifnot(!is.null(swsContext.computationParams$out_coef))
stopifnot(!is.null(swsContext.computationParams$year))

##+ init

## **Flow chart:**
##
## ![Aggregate complete_tf to total_trade](assets/diagram/trade_3.png?raw=true "livestock Flow")

# Settings ####

# Should we do just pre-processing reports?
# If TRUE no auxiliary files will be read (unless they are required)
# and the module will stop as soon as reports on raw data are done.
only_pre_process <- FALSE

# If this is set to TRUE, the module will download the whole dataset
# saved on SWS (year specific) and will do a setdiff by comparing this
# set and the dataset generated by the module: all values saved on SWS
# that are not generated by the current run should be considered "wrong"
# (e.g., generated by a previous run of the module that had a bug) and
# will then be set to NA. See issue #164
remove_nonexistent_transactions <- TRUE

# If set to TRUE, an automatic HS6 mapping will be created so that
# unmapped codes with normal mapped can be recovered with HS6 codes
generate_hs6mapping <- TRUE

# Package build ID (it is included into report directory name)
build_id <- "master"

# Should we stop after HS-CPC mapping?
stop_after_mapping <- FALSE

set.seed(2507)

# Size for sampling. Set NULL if no sampling is required.
samplesize <- NULL

# Logging level. There are following levels (`trace` shows everything in log):
# trace, debug, info, warn, error, fatal

# Additional logger for technical data
futile.logger::flog.logger("dev", "TRACE")
futile.logger::flog.threshold("TRACE", name = "dev")

# Parallel backend will be used only if required packages are installed.
# It will be switched to FALSE if packages are not available.
multicore <- TRUE

## If TRUE, reported values will be in $, if FALSE in k$
dollars <- FALSE

# If TRUE, impute outliers, if FALSE no imputation occurs
detect_outliers <- FALSE

# Print general log to console
general_log2console <- FALSE

# Save current options (will be reset at the end)
old_options <- options()

dev_sws_set_file <- "modules/complete_tf_cpc/sws.yml"

# Switch off dplyr's progress bars globally
options(dplyr.show_progress = FALSE)

# max.print in RStudio is too small
options(max.print = 99999L, scipen = 999)

# Development (SWS-outside) mode addons ####
if (faosws::CheckDebug()){
  set_sws_dev_settings(dev_sws_set_file)
} else {
  # In order to have all columns aligned. Issue #119
  options(width = 1000L)

  # Remove domain from username
  USER <- regmatches(
    swsContext.username,
    regexpr("(?<=/).+$", swsContext.username, perl = TRUE)
  )

  options(error = function(){
    dump.frames()

    filename <- file.path(Sys.getenv("R_SWS_SHARE_PATH"),
                          USER,
                          "complete_tf_cpc")

    dir.create(filename, showWarnings = FALSE, recursive = TRUE)

    save(last.dump, file = file.path(filename, "last.dump.RData"))
  })
}

stopifnot(!any(is.na(USER), USER == ""))

# Read SWS module run parameters ####

##' # Parameters

# Below the calls to `exists()` is useful if it the parameters
# were set in an interactive session

##' - `year`: year for processing.
if (!exists('year', inherits = FALSE)) {
  year <- as.integer(swsContext.computationParams$year)
}
flog.info("Year: %s", year)

# ##' - `out_coef`: coefficient for outlier detection, i.e., the `k` parameter in
# ##' the *Outlier Detection and Imputation* section.
# # See coef argument in ?boxplot.stats
# if (!exists('out_coef', inherits = FALSE)) {
#   out_coef <- as.numeric(swsContext.computationParams$out_coef)
# }
# Note: the outlier detection/imputation is harcoded to be disabled.
# In any case, the coefficient if left here if eventually required.
out_coef <- 1000
# flog.info("Coefficient for outlier detection: %s", out_coef)

if (!CheckDebug()) {
  updateInfoTable(year = year, table = 'complete_tf_runs_info',
                  mode = 'restart')
}

reportdir <- reportdirectory(USER, year, build_id, browsedir = CheckDebug())
report_txt <- file.path(reportdir, "report.txt")
dev_log <- file.path(reportdir, "development.log")

# Send general log messages
if (general_log2console) {
  # to console and a file
  flog.appender(appender.tee(report_txt))
} else {
  # to a file only
  flog.appender(appender.file(report_txt))
}

# Send technical log messages to a file and console
flog.appender(appender.tee(dev_log), name = "dev")

flog.info("SWS-session is run by user %s", USER, name = "dev")

flog.debug("User's computation parameters:",
           swsContext.computationParams, capture = TRUE,
           name = "dev")

flog.info("R session environment: ",
           sessionInfo(), capture = TRUE, name = "dev")

PID <- Sys.getpid()

# Check that all packages are up to date ####

check_versions(c('faoswsUtil', 'faoswsTrade', 'dplyr'),
               c('0.2.11',     '0.1.1',       '0.5.0'))

# Register CPU cores ####
if (multicore) multicore <- register_cpu_cores()

##+ swsdebug

## ## local data
## install.packages("//hqfile4/ess/Team_working_folder/A/SWS/faosws_0.8.2.9901.tar.gz",
##                  repos = NULL,
##                  type = "source")
## ## SWS data
## install.packages("faosws",
##                  repos = "http://hqlprsws1.hq.un.fao.org/fao-sws-cran/")

##+ hschapters, eval = TRUE

hs_chapters <- c(1:24, 33, 35, 38, 40:41, 43, 50:53) %>%
  formatC(width = 2, format = "d", flag = "0") %>%
  as.character %>%
  shQuote(type = "sh") %>%
  paste(collapse = ", ")

##'   - `hs_chapters`: can not be set by the user as it is provided by
##'   Team B/C and hardcoded). The HS chapters are the following:

##'     `r paste(formatC(hs_chapters, width = 2, format = "d", flag = "0"), collapse = ' ')`

##'

flog.info("HS chapters to be selected:", hs_chapters,  capture = TRUE)

##' # Download auxiliary tables

# If running the whole module (only_pre_process = FALSE) the various
# helper files will be read before everything else and a check will
# be done so that if there is any issue in reading any of these tables
# the module should exit immediately (i.e., it makes no sense to read
# the whole trade data, do computations, etc. if the module is going
# to fail because a table could not be read at some later step).
# They are in ordered based on increasing time required for reading.

# TODO: there are basic checks on the tables (mainly that they have
# data), but more detailed checks should be needed (see #132)

if (!only_pre_process) {
##' - `comtradeunits`: Translation of the `qunit` variable (supplementary
##' quantity units) in Tariffline data into intelligible unit of measurement,
##' which correspond to the standards of quantity recommended by the *World
##' Customs Organization* (WCO) (e.g., `qunit`=8 corresponds to *kg*).
##' See: http://unstats.un.org/unsd/tradekb/Knowledgebase/UN-Comtrade-Reference-Tables

  flog.trace("[%s] Reading in 'comtradeunits' datatable", PID, name = "dev")
  comtradeunits <- ReadDatatable('comtradeunits')
  stopifnot(nrow(comtradeunits) > 0)

  #data("comtradeunits", package = "faoswsTrade", envir = environment())
  comtradeunits <- tbl_df(comtradeunits) %>%
    dplyr::rename(
      qunit = ctu_qunit,
      wco   = ctu_wco,
      desc  = ctu_desc
    ) %>%
    dplyr::mutate(qunit = as.integer(qunit))

##' - `EURconversionUSD`: Annual EUR/USD currency exchange rates table from SWS.

  flog.trace("[%s] Reading in 'eur_conversion_usd' datatable", PID, name = "dev")
  EURconversionUSD <- ReadDatatable('eur_conversion_usd')
  stopifnot(nrow(EURconversionUSD) > 0)
  stopifnot(year %in% EURconversionUSD$eusd_year)

  EURconversionUSD <- EURconversionUSD # already downloaded

##' - `finalunits`: For UNSD Tariffline units of measurement are converted to
##' meet FAO standards. According to FAO standard, all weights are reported in
##' tonnes, animals in heads or 1000 heads and for certain commodities,
##' only the value is provided.

  flog.trace("[%s] Reading in 'finalunits' datatable", PID, name = "dev")
  #finalunits <- ReadDatatable('finalunits')
  finalunits <- readRDS('c:/Users/mongeau/tmp/hs2cpc/finalunits.rds')
  stopifnot(nrow(finalunits) > 0)
  # XXX Note: there are two FCL codes that have no associated CPC:
  # 389 (Tomatojuice Concentrated) and 1159 (Offals of Other Camelids)
  finalunits <- filter(finalunits, !is.na(cpc))

  finalunits <- tbl_df(finalunits) %>%
    dplyr::mutate(fcl = as.integer(fcl))

##' - `fcl_codes`: List of valid FCL codes.

  #### XXX: is there a "unique"list of codes?

  flog.trace("[%s] Reading in 'fcl_codes' datatable", PID, name = "dev")
  fcl_codes_1 <- ReadDatatable('fcl_2_cpc')$fcl
  stopifnot(length(fcl_codes_1) > 0)
  fcl_codes_2 <- ReadDatatable('fcl2cpc_ver_2_1')$fcl
  stopifnot(length(fcl_codes_2) > 0)
  fcl_codes <- unique(c(fcl_codes_1, fcl_codes_2))
  fcl_codes <- fcl_codes[!is.na(fcl_codes)]

  fcl_codes <- as.numeric(fcl_codes)

##' - `cpc_codes`: List of valid CPC codes.

  #### XXX: is there a "unique"list of codes?

  flog.trace("[%s] Reading in 'cpc_codes' datatable", PID, name = "dev")
  cpc_codes_1 <- ReadDatatable('fcl_2_cpc')$cpc
  stopifnot(length(cpc_codes_1) > 0)
  cpc_codes_2 <- ReadDatatable('fcl2cpc_ver_2_1')$cpc
  stopifnot(length(cpc_codes_2) > 0)
  cpc_codes <- unique(c(cpc_codes_1, cpc_codes_2))
  cpc_codes <- cpc_codes[!is.na(cpc_codes)]

##' - `livestock_weights`: Table with livestock weights.

  flog.trace("[%s] Reading in 'livestock_weights' datatable", PID, name = "dev")
  #livestock_weights <- ReadDatatable('livestock_weights')
  livestock_weights <- readRDS('c:/Users/mongeau/tmp/hs2cpc/livestock_weights.rds')
  stopifnot(nrow(livestock_weights) > 0)

##' - `hs6standard`: HS6standard will be used as last resort for mapping.

  flog.trace("[%s] Reading in 'standard_hs12_6digit' datatable", PID, name = "dev")
  hs6standard <- ReadDatatable('standard_hs12_6digit')
  stopifnot(nrow(hs6standard) > 0)

  hs6standard <- hs6standard %>%
    group_by(hs2012_code) %>%
    dplyr::filter(n() == 1) %>%
    ungroup() %>%
    dplyr::mutate(hs6 = as.integer(hs2012_code)) %>%
    dplyr::select(hs6, hs2012_code, faostat_code) %>%
    # XXX This is done here after the requirement of going
    # straight to CPC, but it's probably better to have the
    # codes already in the SWS datatable.
    dplyr::mutate(cpc_code = fcl2cpc(stringr::str_pad(faostat_code, 4, 'left', 0), version = '2.1'))

##' - `hscpcmap_extension`: Additional mapping between HS and CPC codes (extends `hscpcmap_main`).

  flog.trace("[%s] Reading in 'hscpcmap_extension' datatable", PID, name = "dev")
  #add_map <- ReadDatatable('hscpcmap_extension')
  add_map <- readRDS('c:/Users/mongeau/tmp/hs2cpc/hscpcmap_extension.rds')
  # XXX following codes were not converted to CPC:
  #                  389  134 1360 1239 1189  823
  stopifnot(nrow(add_map) > 0)

  add_map <- tbl_df(add_map) %>%
    dplyr::filter(!is.na(year), !is.na(reporter_fao), !is.na(hs)) %>%
    dplyr::mutate(
      hs = ifelse(
             hs_chap < 10 & stringr::str_sub(hs, 1, 1) != '0',
             paste0('0', formatC(hs, format = 'fg')),
             formatC(hs, format = 'fg')
           ),
      hs = stringr::str_replace_all(hs, ' ', '')
    ) %>%
    dplyr::arrange(reporter_fao, flow, hs, year)

  ## XXX change some FCL codes that are not valid
  add_map <- add_map %>%
    dplyr::mutate(fcl = ifelse(fcl == 389, 390, fcl)) %>%
    dplyr::mutate(fcl = ifelse(fcl == 654, 653, fcl))

##' - `hscpcmap_main`: Mapping between HS and CPC codes extracted from MDB
##' files used to archive information existing in the previous trade system
##' (Shark/Jellyfish). This mapping table contains (identifier: `hscpcmap`)
##' also some "corrections" to the original mapping found in the MDB files.
##' These are contained in the `correction_*` variables (e.g.,
##' `corrections_endyear`), and if for a given HS range one or more of these
##' variables are non-missing they will replace the original corresponding
##' variable (e.g., if `corresponding_endyear` is non-missing, it will replace
##' `endyear`). Missing HS to CPC links in the MDB files are mapped by Team B/C
##' and stored in a table (identifier: `hscpcmap_extension`) that will extend
##' the original mapping table. The resulting mapping table gets subsetted with
##' th econdition that the`startyear` and `endyear` of the HS to CPC links
##' should satisfy the condition: $startyear <= year <= endyear$.

  flog.trace("[%s] Reading in 'hscpcmap_main' datatable", PID, name = "dev")
  #hscpcmap_main <- ReadDatatable('hscpcmap_main')
  hscpcmap_main <- readRDS('c:/Users/mongeau/tmp/hs2cpc/hscpcmap_main.rds')
  stopifnot(nrow(hscpcmap_main) > 0)

##' - `force_mirroring`: Datatables for those reported that need to be
##' treated as non-reporters as mirroring is required.

  flog.trace("[%s] Reading in 'force_mirroring' datatable", PID, name = "dev")
  force_mirroring <- ReadDatatable('force_mirroring')
  stopifnot(nrow(force_mirroring) > 0)

##' - `corrections_table`: Table with corrections applied during the
##' validation process.

  flog.trace("[%s] Reading in corrections dataset", PID, name = "dev")
  corrections_dir <-
    file.path(Sys.getenv('R_SWS_SHARE_PATH'), 'trade/validation_tool_files')

  # Corrections are stored into single-country files
  corrections_table_all <-
    lapply(
      dir(corrections_dir, pattern = '^[0-9]+$'),
      function(x) readRDS(
        file.path(corrections_dir, x, 'corrections_table.rds')
      )
    ) %>%
    do.call(rbind, .)

  # Check whether the folder where the unapplied corrections
  # are going to be stored exists, if not then create it
  if (!file.exists(file.path(corrections_dir, 'unapplied'))) {
    dir.create(file.path(corrections_dir, 'unapplied'), recursive = TRUE)
  }

}

# (unsdpartnersblocks is required in pre-processing)
#
##' - `unsdpartnersblocks`: UNSD Tariffline reporter and partner dimensions use
##' different list of geographic are codes. The partner dimension is more
##' detailed than the reporter dimension. Since we can not split trade flows of
##' the reporter dimension, trade flows of the corresponding partner dimensions
##' have to be assigned the reporter dimension's geographic area code. For
##' example, the code 842 is used for the United States includes Virgin Islands
##' and Puerto Rico and thus the reported trade flows of those territories.
##' Analogous steps are taken for France, Italy, Norway, Switzerland and US
##' Minor Outlying Islands.

flog.trace("[%s] Reading in unsdpartnersblocks datatable", PID, name = "dev")
unsdpartnersblocks <- ReadDatatable('unsdpartnersblocks')
stopifnot(nrow(unsdpartnersblocks) > 0)

unsdpartnersblocks <- tbl_df(unsdpartnersblocks)


##' # Download raw data and basic operations

##' 1. Download Eurostat data (ES) available in
##' `trade-input-data:ce_combinednomenclature_unlogged_YEAR`
##' datatables (label: "EU Commission - Combined Nomenclature YEAR").

flog.trace("[%s] Reading in Eurostat data", PID, name = "dev")

#esdata <- ReadDatatable(
#  paste0("ce_combinednomenclature_unlogged_", year),
#  columns = c(
#    "period",
#    "declarant",
#    "partner",
#    "flow",
#    "product_nc",
#    "value_1k_euro",
#    "qty_ton",
#    "sup_quantity",
#    "stat_regime"
#  ),
#  where = paste0("chapter IN (", hs_chapters, ")")
#) %>% tbl_df()
esdata <- readRDS(paste0('c:/Users/mongeau/data_qa/ce_combinednomenclature_unlogged_', year, '.rds'))

stopifnot(nrow(esdata) > 0)

# Sample, if required

if (!is.null(samplesize)) {
  esdata <- sample_n(esdata, samplesize)
  warning(sprintf("Eurostat data was sampled with size %d", samplesize))
}

flog.info("Raw Eurostat data preview:", rprt_glimpse0(esdata), capture = TRUE)

##' 1. Download Tariff line data (TL) available in
##' `trade-input-data:ct_tariffline_unlogged_YEAR`
##' datatables (label: "UNSD Tariffline YEAR").

flog.trace("[%s] Reading in Tariffline data", PID, name = "dev")

#tldata <- ReadDatatable(
#  paste0("ct_tariffline_unlogged_", year),
#  columns = c(
#    "tyear",
#    "rep",
#    "prt",
#    "flow",
#    "comm",
#    "tvalue",
#    "weight",
#    "qty",
#    "qunit",
#    "chapter"
#  ),
#  where = paste0("chapter IN (", hs_chapters, ")")
#) %>% tbl_df()
tldata <- readRDS(paste0('c:/Users/mongeau/data_qa/ct_tariffline_unlogged_', year, '.rds'))

stopifnot(nrow(tldata) > 0)

# Sample, if required

if (!is.null(samplesize)) {
  tldata <- sample_n(tldata, samplesize)
  warning(sprintf("Tariffline data was sampled with size %d", samplesize))
}

flog.info("Raw Tariffline data preview:", rprt_glimpse0(tldata), capture = TRUE)

##' 1. Keep only `stat_regime` = 4 in ES.

##' 1. Remove European-aggregated data (i.e., totals) from ES.

## Only regime 4 is relevant for Eurostat data
esdata <- esdata %>%
  filter_(~stat_regime == "4") %>%
  ## Removing stat_regime as it is not needed anymore
  select_(~-stat_regime) %>%
  # Remove totals, 1010 = 'European Union', 1011 = 'Extra-European Union', see
  # http://ec.europa.eu/eurostat/documents/3859598/5889816/KS-BM-05-002-EN.PDF
  filter_(~!(declarant == 'EU' | partner %in% c('1010', '1011')))

flog.info("Records after removing 4th regime and EU totals: %s", nrow(esdata))

##' 1. Use standard (common) variable names (e.g., `declarant` becomes `reporter`) in ES and TL.

esdata <- adaptTradeDataNames(esdata)
tldata <- adaptTradeDataNames(tldata)

esdata <- mutate_(esdata, hs6 = ~as.integer(str_sub(hs, 1, 6)))
tldata <- mutate_(tldata, hs6 = ~as.integer(str_sub(hs, 1, 6)))

##' 1. Filter HS codes of interest, i.e., codes that do not
##' participate in further processing. Such solution drops,
##' e.g., all HS codes shorter than 6 digits.

esdata <- filterHS6FAOinterest(esdata)
tldata <- filterHS6FAOinterest(tldata)

##' 1. Remove non numeric reporters / partners / hs codes from ES and TL.

esdata <- removeNonNumeric(esdata)
tldata <- removeNonNumeric(tldata)

##' 1. Use standard (common) variable types in ES and TL.

esdata <- adaptTradeDataTypes(esdata)
tldata <- adaptTradeDataTypes(tldata)

##' 1. Apply specific HS corrections. Some HS codes in some countries
##' need specific HS corrections. As on 2018-03-08 only a subset of
##' HS codes for a given TL reporter are corrected (tonnes were reported
##' instead of kilograms, so raw data was multiplied by 1000).

# XXX As of 20171130 this is relevant only for a given reporter in
# a given year, but in the future it should probably be generalised

# esdata <- specificCorrectionsHS(esdata)
tldata <- specificCorrectionsHS(tldata)

##' 1. Convert ES geonomenclature country/area codes to FAO codes.

##+ geonom2fao
esdata <- esdata %>%
  dplyr::mutate(
    reporter = convertGeonom2FAO(reporter),
    partner  = convertGeonom2FAO(partner)
  ) %>%
  # XXX issue 147
  dplyr::filter(!is.na(partner))


# M49 to FAO area list ####

##' 1. TL M49 codes (which are different from official M49) are
##' converted in FAO country codes using a specific conversion
##' table (`unsdpartnersblocks`) provided by Team ENV. Then,
##' these M49 codes are converted to FAO codes.

flog.trace("[%s] TL: converting M49 to FAO area list", PID, name = "dev")

tldata <- tldata %>%
  left_join(
    unsdpartnersblocks %>%
      select_(
        wholepartner = ~unsdpb_rtcode,
        part         = ~unsdpb_formula
      ) %>%
      dplyr::mutate(
        wholepartner = as.numeric(wholepartner),
        part         = as.numeric(part)
      ) %>%
      # Exclude EU grouping and old countries
      filter_(
        ~wholepartner %in% c(251, 381, 579, 581, 757, 842)
      ),
    by = c("partner" = "part")
  ) %>%
  dplyr::mutate_(
    partner  = ~ifelse(is.na(wholepartner), partner, wholepartner),
    m49rep   = ~reporter,
    m49par   = ~partner,
    # Conversion from Comtrade M49 to FAO area list
    reporter = ~as.integer(convertComtradeM49ToFAO(m49rep)),
    partner  = ~as.integer(convertComtradeM49ToFAO(m49par))
  )

##' 1. Remove invalid reporters (i.e., keep countries/areas that
##' existed in the year considered).

tldata <- removeInvalidReporters(tldata)

##' 1. Force mirroring, i.e., remove countries that appear as official
##' reporters so that the mirroring procedure will estimate their data.

esdata <-
  anti_join(
    esdata,
    force_mirroring,
    by = c('reporter' = 'fao_code', 'year')
  )

tldata <-
  anti_join(
    tldata,
    force_mirroring,
    by = c('reporter' = 'fao_code', 'year')
  )

##' 1. Remove ES reporters from TL.

flog.trace("[%s] TL: dropping reporters already found in Eurostat data", PID, name = "dev")
# They will be replaced by ES data
tldata <- tldata %>%
  anti_join(
    esdata %>%
      select_(~reporter) %>%
      distinct(),
    by = "reporter"
  )

# XXX create all reporters

tldata_rep_table <- tldata %>%
  dplyr::select(reporter, flow) %>%
  distinct() %>%
  dplyr::mutate(name = faoAreaName(reporter, "fao"))

rprt_writetable(tldata_rep_table, subdir = 'preproc')

# XXX this is a duplication: a function should be created.
to_mirror_raw <- bind_rows(
    dplyr::select(esdata, year, reporter, partner, flow),
    dplyr::select(tldata, year, reporter, partner, flow)
  ) %>%
  dplyr::mutate(flow = recode(flow, '4' = 1L, '3' = 2L)) %>%
  flowsToMirror(names = TRUE)

rprt_writetable(to_mirror_raw, 'flows', subdir = 'preproc')

if (only_pre_process) stop("Stop after reports on raw data")

##' 1. Apply explicit corrections to the HS-FCL mapping.

hscpcmap_main <- tbl_df(hscpcmap_main) %>%
  # CPC, startyear, endyear codes can be overwritten by corrections
  dplyr::mutate(
    fcl       = ifelse(!is.na(correction_fcl), correction_fcl, fcl),
    cpc       = ifelse(!is.na(correction_cpc), correction_cpc, cpc),
    startyear = ifelse(!is.na(correction_startyear), correction_startyear, startyear),
    endyear   = ifelse(!is.na(correction_endyear), correction_endyear, endyear)
  ) %>%
  dplyr::select(-starts_with('correction'))

##' 1. Extend the `endyear` for those combinations of `area` / `flow` /
##' `fromcode` / `tocode` for which `endyear` < `year`.

# Extend endyear to 2050
hscpcmap_main <-
  hscpcmap_main %>%
  group_by(area, flow, fromcode, tocode) %>%
  dplyr::mutate(maxy = max(endyear), extend = ifelse(maxy < 2050, TRUE, FALSE)) %>%
  ungroup() %>%
  dplyr::mutate(endyear = ifelse(endyear == maxy & extend, 2050, endyear)) %>%
  dplyr::select(-maxy, -extend)
# / Extend endyear to 2050


# ADD UNMAPPED CODES

# Check that all FCL codes are valid

fcl_diff <- setdiff(unique(add_map$fcl), fcl_codes)

fcl_diff <- fcl_diff[!is.na(fcl_diff)]

fcl_diff <- setdiff(fcl_diff, 0)

if (length(fcl_diff) > 0) {
    warning(paste('Invalid FCL codes:', paste(fcl_diff, collapse = ', ')))
}

# Check that all CPC codes are valid

cpc_diff <- setdiff(unique(add_map$cpc), cpc_codes)

cpc_diff <- cpc_diff[!is.na(cpc_diff)]

cpc_diff <- setdiff(cpc_diff, 0)

if (length(cpc_diff) > 0) {
    warning(paste('Invalid CPC codes:', paste(cpc_diff, collapse = ', ')))
}


# Check that years are in a valid range

if (min(add_map$year) < 2000) {
  warning('The minimum year should not be lower than 2000.')
}

if (max(add_map$year) > as.numeric(format(Sys.Date(), '%Y'))) {
  warning('The maximum year should not be greater than the current year.')
}

# Check that there are no duplicate codes

tmp <- add_map %>%
  dplyr::count(reporter_fao, year, flow, hs) %>%
  dplyr::filter(n > 1)

if (nrow(tmp) > 0) {
  warning('Removing duplicate HS codes by reporter/year/flow.')
  
  # XXX
  add_map <- add_map %>%
    group_by(reporter_fao, year, flow, hs) %>%
    dplyr::mutate(hs_ext_perc = sum(!is.na(hs_extend))/n()) %>%
    # Prefer cases where hs_extend is available
    dplyr::filter(hs_ext_perc == 0 | (hs_ext_perc > 0 & !is.na(hs_extend) & n() == 1)) %>%
    ungroup() %>%
    dplyr::select(-hs_ext_perc)
}

# Raise warning if countries were NOT in mapping.

if (length(setdiff(unique(add_map$reporter_fao), hscpcmap_main$area)) > 0) {
  warning('Some countries were not in the original mapping.')
}

add_map <- add_map %>%
  dplyr::mutate(
    startyear  = year,
    endyear    = 2050L,
    fromcode   = hs,
    tocode     = hs,
    recordnumb = NA_integer_
  ) %>%
  dplyr::select(
    area = reporter_fao,
    flow,
    fromcode,
    tocode,
    fcl,
    cpc,
    startyear,
    endyear,
    recordnumb,
    details,
    tl_description
  )

max_record <- max(hscpcmap_main$recordnumb)

add_map$recordnumb <- (max_record+1):(max_record+nrow(add_map))

add_map <- add_map %>%
  dplyr::select(-details, -tl_description) %>%
  dplyr::mutate(
    fcl      = as.numeric(fcl),
    fromcode = gsub(' ', '', fromcode),
    tocode   = gsub(' ', '', tocode)
  )

##' 1. Add additional codes that were not present in the HS-
##' original mapping file.

hscpcmap_main <- bind_rows(add_map, hscpcmap_main) %>%
  dplyr::mutate(
    startyear = as.integer(startyear),
    endyear   = as.integer(endyear)
  )

# / ADD UNMAPPED CODES

flog.info("HS->CPC mapping table preview:",
          rprt_glimpse0(hscpcmap_main), capture = TRUE)

rprt(hscpcmap_main, "hscpcmap", year)

##' 1. Keep HS-FCL links for which `startyear` <= `year` & `endyear` >= `year`

hscpcmap <- hscpcmap_main %>%
  filter_(~startyear <= year & endyear >= year) %>%
  select_(~-startyear, ~-endyear)

# Workaround issue #123
hscpcmap <- hscpcmap %>%
  dplyr::mutate_at(vars(ends_with("code")), funs(num = as.numeric)) %>%
  dplyr::mutate_(fromgtto = ~fromcode_num > tocode_num) %>%
  dplyr::select(-ends_with("code_num"))

from_gt_to <- hscpcmap$recordnumb[hscpcmap$fromgtto]

if (length(from_gt_to) > 0)
  flog.warn(paste0("In following records of hscpcmap fromcode greater than tocode: ",
                 paste0(from_gt_to, collapse = ", ")))

hscpcmap <- hscpcmap %>%
  filter_(~!fromgtto) %>%
  select_(~-fromgtto)

stopifnot(nrow(hscpcmap) > 0)

flog.info("Rows in mapping table after dplyr::filtering by year: %s", nrow(hscpcmap))

##' 1. Generate HS to FCL map at HS6 level (if switched on)

if (generate_hs6mapping) {

# hs6cpcmap ####

  flog.trace("[%s] Extraction of HS6 mapping table", PID, name = "dev")

##'     1. Universal (all years) HS6 mapping table.

  flog.trace("[%s] Universal (all years) HS6 mapping table", PID, name = "dev")

  hs6cpcmap_full <- extract_hs6cpcmap(hscpcmap_main)

##'     1. Current year specific HS6 mapping table.

  flog.trace("[%s] Current year specific HS6 mapping table", PID, name = "dev")

  hs6cpcmap_year <- extract_hs6cpcmap(hscpcmap)

  hs6cpcmap <- bind_rows(hs6cpcmap_full, hs6cpcmap_year) %>%
    filter_(~cpc_links == 1L) %>%
    distinct()

} else {

  # A dummy zero-row dataframe needs to be created
  hs6cpcmap <-
    data_frame(
      reporter  = integer(),
      flow      = integer(),
      hs6       = integer(),
      fcl       = double(),
      cpc       = character(),
      cpc_links = integer(),
    )

}

rprt(hs6cpcmap, "hs6cpcmap")

##' # Specific operations on Eurostat data

##' 1. Add variables that will contain flags. (Note: flags are set in various
##' steps in the code. Please, refer to the "Flag Management in the Trade module"
##' document.)

esdata <- generateFlagVars(esdata)


esdata <- esdata %>%
  setFlag3(!is.na(value),  type = 'status', flag = 'X', variable = 'value') %>%
  setFlag3(!is.na(weight), type = 'status', flag = 'X', variable = 'weight') %>%
  setFlag3(!is.na(qty),    type = 'status', flag = 'X', variable = 'quantity') %>%
  setFlag3(!is.na(value),  type = 'method', flag = 'h', variable = 'value') %>%
  setFlag3(!is.na(weight), type = 'method', flag = 'h', variable = 'weight') %>%
  setFlag3(!is.na(qty),    type = 'method', flag = 'h', variable = 'quantity')


##' 1. Remove in ES those reporters with area codes that are not included in
##' MDB commodity mapping area list.

##+ es-treat-unmapped
esdata_not_area_in_cpc_mapping <- esdata %>%
  filter_(~!(reporter %in% unique(hscpcmap$area)))

rprt_writetable(esdata_not_area_in_cpc_mapping)

esdata <- filter_(esdata, ~reporter %in% unique(hscpcmap$area))

flog.info("Records after removing areas not in HS->CPC map: %s", nrow(esdata))

# ES trade data mapping to CPC ####
message(sprintf("[%s] Convert Eurostat HS to CPC", PID))

##' 1. Map HS codes to CPC

##'     1. Extract HS6-CPC mapping table.

esdatahs6links <- mapHS6toCPC(esdata, hs6cpcmap)

##'     1. Extract specific HS-CPC mapping table.

esdatalinks <- mapHS2CPC(tradedata   = esdata,
                         maptable    = hscpcmap_main,
                         hs6maptable = hs6cpcmap,
                         year        = year,
                         parallel    = multicore)

##'     1. Use HS6-CPC or HS-CPC mapping table.

esdata <- add_cpcs_from_links(esdata,
                              hs6links = esdatahs6links,
                              links    = esdatalinks)

##'     1. Use HS6 standard for unmapped codes.

esdata <- esdata %>%
  left_join(
    hs6standard %>% dplyr::select(-hs2012_code),
    by = 'hs6'
  ) %>%
  dplyr::mutate(
    fcl = ifelse(is.na(fcl) & !is.na(faostat_code), faostat_code, fcl),
    cpc = ifelse(is.na(cpc) & !is.na(cpc_code),     cpc_code,     cpc)
  ) %>%
  dplyr::select(-faostat_code, -cpc_code)

flog.info("Records after HS-CPC mapping: %s", nrow(esdata))

rprt(esdata, "hs2cpc_fulldata", tradedataname = "esdata")

flog.trace("[%s] ES: dropping unmapped records", PID, name = "dev")

##' 1. Remove unmapped CPC codes (i.e., transactions with no HS to CPC link).

esdata <- filter_(esdata, ~!(is.na(cpc)))

flog.info("ES records after removing non-mapped HS codes: %s", nrow(esdata))

##' 1. Add final units, i.e., the target units of measurement of the items
##' (e.g., tonnes, heads).

esdata <- addFinalUnits(tradedata = esdata, finalunits = finalunits)

##' 1. Specific conversions: some FCL codes are reported in Eurostat
##' with different supplementary units than those reported in FAOSTAT,
##' thus a conversion is done.

## specific supplementary unit conversion
es_spec_conv <- frame_data(
     ~cpc,  ~fcl, ~conv,
  "02151", 1057L, 0.001,
  "02154", 1068L, 0.001,
  "02153", 1072L, 0.001,
  "02152", 1079L, 0.001,
  "02194", 1083L, 0.001,
  "02191", 1140L, 0.001,
  "02196", 1181L, 1000
)

esdata <- esdata %>%
  left_join(es_spec_conv, by = c('cpc', 'fcl')) %>%
  dplyr::mutate_(qty = ~ifelse(is.na(conv), qty, qty*conv)) %>%
  setFlag3(!is.na(conv), type = 'method', flag = 'i', variable = 'quantity') %>%
  select_(~-conv)

##' # Specific operations on Tariff line data

##' 1. Do mathematical conversions on specific `qunit`s: 6 (pairs),
##' 9 (thousands), and 11 (dozens) become 5 (units), by multiplying
##' them by 2, 1000, and 12, respectively.

# Convert qunit 6, 9, and 11 to 5 (mathematical conversion)
tldata <- as.data.table(tldata)
tldata[qunit ==  6, c('qty', 'qunit') := list(   qty*2, 5)]
tldata[qunit ==  9, c('qty', 'qunit') := list(qty*1000, 5)]
tldata[qunit == 11, c('qty', 'qunit') := list(  qty*12, 5)]
tldata <- tbl_df(tldata)

# tl-aggregate-multiple-rows ####

##' 1. Identical combinations of `reporter` / `partner` / `commodity` /
##' `flow` / `year` / `qunit` are pre-aggregated.

flog.trace("[%s] TL: aggreation of similar flows", PID, name = "dev")

tldata <- preAggregateMultipleTLRows(tldata)

##' 1. Add variables that will contain flags. (Note: flags are set in various
##' steps in the code. Please, refer to the "Flag Management in the Trade module"
##' document.)

flog.trace("[%s] TL: add flag variables")
tldata <- generateFlagVars(tldata)

tldata <- tldata %>%
  setFlag3(nrows > 1, type = 'method', flag = 's', variable = 'all')


tldata <- tldata %>%
  setFlag3(!is.na(value),  type = 'status', flag = 'X', variable = 'value') %>%
  setFlag3(!is.na(weight), type = 'status', flag = 'X', variable = 'weight') %>%
  setFlag3(!is.na(qty),    type = 'status', flag = 'X', variable = 'quantity') %>%
  setFlag3(!is.na(value),  type = 'method', flag = 'h', variable = 'value') %>%
  setFlag3(!is.na(weight), type = 'method', flag = 'h', variable = 'weight') %>%
  setFlag3(!is.na(qty),    type = 'method', flag = 'h', variable = 'quantity')


##+ drop_reps_not_in_mdb ####

##' 1. Area codes not mapping to any FAO country in the HS to CPC mapping
##' codes are removed.

# We drop reporters that are absent in MDB hscpc map
# because in any case we can proceed their data

tldata_not_area_in_cpc_mapping <- tldata %>%
  filter_(~!(reporter %in% unique(hscpcmap$area)))

rprt_writetable(tldata_not_area_in_cpc_mapping)

flog.trace("[%s] TL: dropping reporters not found in the mapping table", PID, name = "dev")
tldata <- filter_(tldata, ~reporter %in% unique(hscpcmap$area))

##+ reexptoexp ####
##' 1. Re-imports become imports and re-exports become exports.
flog.trace("[%s] TL: recoding reimport/reexport", PID, name = "dev")

# { "id": "1", "text": "Import" },
# { "id": "2", "text": "Export" },
# { "id": "4", "text": "re-Import" },
# { "id": "3", "text": "re-Export" }

tldata <- dplyr::mutate_(tldata, flow = ~recode(flow, '4' = 1L, '3' = 2L))

##' 1. Map HS codes to CPC.
##+ tl_hs2cpc ####

##'     1. Extract HS6-CPC mapping table.

tldatahs6links <- mapHS6toCPC(tldata, hs6cpcmap)

##'     1. Extract specific HS-CPC mapping table.

tldatalinks <- mapHS2CPC(tradedata   = tldata,
                         maptable    = hscpcmap_main,
                         hs6maptable = hs6cpcmap,
                         year        = year,
                         parallel    = multicore)

##'     1. Use HS6-CPC or HS-CPC mapping table.

# XXX hs2cpc: these two CPC codes have no CPC codes: 389, 1599
tldata <- add_cpcs_from_links(tldata,
                              hs6links = tldatahs6links,
                              links    = tldatalinks)

##'     1. Use HS6 starndard for unmapped codes.

tldata <- tldata %>%
  left_join(
    hs6standard %>% dplyr::select(-hs2012_code),
    by = 'hs6'
  ) %>%
  dplyr::mutate(
    fcl = ifelse(is.na(fcl) & !is.na(faostat_code), faostat_code, fcl),
    cpc = ifelse(is.na(cpc) & !is.na(cpc_code),     cpc_code,     cpc)
  ) %>%
  dplyr::select(-faostat_code, -cpc_code)

flog.info("Records after HS-CPC mapping: %s", nrow(tldata))

rprt(tldata, "hs2cpc_fulldata", tradedataname = "tldata")

flog.trace("[%s] TL: dropping unmapped records", PID, name = "dev")

##' 1. Remove unmapped CPC codes (i.e., transactions with no HS to CPC link).

tldata <- filter_(tldata, ~!is.na(cpc))

flog.info("TL records after removing non-mapped HS codes: %s", nrow(tldata))

if (stop_after_mapping) stop("Stop after HS->CPC mapping")

############# Units of measurment in TL ####

##' 1. Add CPC units, i.e., the target units of measurement of the items
##' (e.g., tonnes, heads).

flog.trace("[%s] TL: add CPC units", PID, name = "dev")

tldata <- addFinalUnits(tldata, finalunits = finalunits)

tldata <- tldata %>%
  dplyr::mutate_(qunit = ~as.integer(qunit)) %>%
  left_join(comtradeunits %>% select_(~qunit, ~wco), by = "qunit")

## Dataset with all matches between Comtrade and FAO units
ctfinalunitsconv <- tldata %>%
  select_(~qunit, ~wco, ~finalunit) %>%
  distinct() %>%
  arrange_(~qunit) %>%
  as.data.table()

################ Conv. factor (TL) ################
flog.trace("[%s] TL: conversion factors", PID, name = "dev")

##### Table for conv. factor

##' 1. General conversions: some CPC codes are reported in Tariffline with
##' different units than those reported in FAOSTAT, thus a conversion is done.

ctfinalunitsconv$conv <- 0
# Missing quantity
ctfinalunitsconv[qunit == 1,                               conv :=   NA]
# Missing quantity
ctfinalunitsconv[finalunit == "$ value only",                conv :=   NA]
ctfinalunitsconv[finalunit == "mt"         & wco == "l",     conv := .001]
ctfinalunitsconv[finalunit == "heads"      & wco == "u",     conv :=    1]
ctfinalunitsconv[finalunit == "1000 heads" & wco == "u",     conv := .001]
ctfinalunitsconv[finalunit == "number"     & wco == "u",     conv :=    1]
ctfinalunitsconv[finalunit == "mt"         & wco == "kg",    conv := .001]
ctfinalunitsconv[finalunit == "mt"         & wco == "m³",    conv :=    1]
ctfinalunitsconv[finalunit == "mt"         & wco == "carat", conv := 5e-6]


##### Add conv factor to the dataset

tldata <- left_join(tldata, ctfinalunitsconv, by = c("qunit", "wco", "finalunit"))

##' 1. Specific conversions: some CPC codes are reported in Tariff line
##' with different supplementary units than those reported in FAOSTAT,
##' thus a conversion is done.

#### Commodity specific conversion

# For converting qty to metric tons
cpc_spec_mt_conv <- tldata %>%
  filter_(~finalunit == "mt" & is.na(weight) & conv == 0) %>%
  select_(~cpc, ~fcl, ~wco) %>%
  distinct()

# Reset conv to NA as its zero is not useful anymore
tldata <- tldata %>%
  dplyr::mutate(conv = ifelse(conv == 0, NA, conv))

# For converting weight to 'heads', '1000 heads', 'units'.
cpc_spec_head_conv <- tldata %>%
  dplyr::select(cpc, fcl, finalunit) %>%
  distinct() %>%
  dplyr::filter(finalunit %in% c('heads', '1000 heads', 'units'))

# XXX probably this check should be removed.
if (NROW(cpc_spec_mt_conv) > 0) {

  # weight > mt
  conversion_factors_cpc_mt <- tldata %>%
    dplyr::filter(!is.na(weight) & !is.na(qty)) %>%
    dplyr::mutate(qw = (weight/qty)/1000) %>%
    group_by(cpc, fcl, wco) %>%
    dplyr::summarise(convspec_mt = median(qw, na.rm = TRUE)) %>%
    ungroup()

  cpc_spec_mt_conv <- cpc_spec_mt_conv %>%
    left_join(conversion_factors_cpc_mt, by = c("cpc", "fcl", "wco")) %>%
    # Zero quantities will be imputed
    dplyr::mutate(convspec_mt = ifelse(is.na(convspec_mt), 0, convspec_mt))

  # XXX some weights are missing: e.g., reporter = 20, fcl = 946, year = 2015
  # (reported on FCL as it used to be; needs to be adapted to cpc)
  # They can be imputed as the median of existing weights (see below), but this
  # needs to be discussed:
  #  livestock_weights %>%
  #    unite(fcl_live, fcl, livestock, sep = '#') %>%
  #    complete(reporter_fao, fcl_live) %>%
  #    separate(fcl_live, c('fcl', 'livestock'), sep = '#') %>%
  #    dplyr::mutate(fcl = as.integer(fcl)) %>%
  #    group_by(fcl) %>%
  #    dplyr::mutate(liveweight = ifelse(is.na(liveweight), median(liveweight, na.rm = TRUE), liveweight))

  # weight > heads
  cpc_spec_head_conv <- livestock_weights %>%
    tbl_df() %>%
    dplyr::select(reporter = reporter_fao, cpc, fcl, liveweight) %>%
    left_join(cpc_spec_head_conv, by = c('cpc', 'fcl')) %>%
    dplyr::filter(!is.na(finalunit)) %>%
    dplyr::filter(!is.na(liveweight), liveweight > 0) %>%
    dplyr::rename(convspec_head = liveweight)

  ### Add commodity specific conv.factors to dataset

  tldata <- tldata %>%
    left_join(cpc_spec_mt_conv,   by = c("cpc", "fcl", "wco")) %>%
    left_join(cpc_spec_head_conv, by = c("reporter", "cpc", "fcl", "finalunit"))

  tldata$id <- 1:nrow(tldata)
  tldata$qtycpc <- NA_real_

  tldata_converted <- tldata %>%
    dplyr::mutate(
      qtycpc =
        case_when(
          .$finalunit == 'mt' & !is.na(.$weight)                     ~ .$weight / 1000,
          .$finalunit == 'heads' & !is.na(.$qty) & .$wco == 'u'      ~ .$qty,
          .$finalunit == 'number' & !is.na(.$qty) & .$wco == 'u'     ~ .$qty,
          # This requires a flag change
          .$finalunit == '1000 heads' & !is.na(.$qty) & .$wco == 'u' ~ .$qty / 1000,
          # -1 will be set to NA just below
          .$finalunit == '$ value only'                              ~ -1,
          # Nothing can be done for these
          is.na(.$weight) & is.na(.$qty)                             ~ -1,
          TRUE                                                       ~ .$qtycpc
        )
    ) %>%
    filter(!is.na(qtycpc)) %>%
    dplyr::mutate(qtycpc = ifelse(qtycpc == -1, NA, qtycpc))

  tldata_not_converted <-
    anti_join(tldata, tldata_converted, by = 'id')

  ########## Conversion of units

  #### CPC specific conv

  tldata_to_convert <- tldata_not_converted %>%
    dplyr::mutate(
      qtycpc =
        case_when(
          !is.na(.$convspec_mt)                                 ~ .$qty * .$convspec_mt,
          !is.na(.$convspec_head) & .$finalunit != '1000 heads' ~ .$weight / .$convspec_head,
          !is.na(.$convspec_head) & .$finalunit == '1000 heads' ~ .$weight / .$convspec_head / 1000,
          #### Common conv
          # If no specific conv. factor, we apply general
          TRUE                                                  ~ .$qty * .$conv
        )
    )

  tldata <-
    bind_rows(
      tldata_converted,
      tldata_to_convert
    ) %>%
    # Decimals make no sense for heads
    dplyr::mutate(qtycpc = ifelse(finalunit %in% 'heads', round(qtycpc, 0), qtycpc))

  rm(tldata_converted, tldata_to_convert, tldata_not_converted)
  invisible(gc())

  # Estimation of weight for livestock will be kept for later,
  # especifically after doImputation() has been used.

} else {
  tldata$qtycpc = NA
}

###' 1. If the `weight` variable is available and the final unit
###' of measurement is tonnes then `weight` is used as `quantity`.
## (already done above)
#cond_w <- tldata$finalunit == 'mt' & !is.na(tldata$weight) & tldata$weight > 0
#
#tldata$qtycpc <- ifelse(cond_w, tldata$weight / 1000, tldata$qtycpc)

# Weight is always in tonnes
tldata$weight <- tldata$weight / 1000

# XXX sometimes the condition is TRUE, but it doesn't mean that
# the conversion factors were indeed used. See, e.g.,
# tldata %>% filter(year == 2016, reporter == 154, fcl == 1062)
cond_q <- !is.na(tldata$convspec_mt) | !is.na(tldata$convspec_head)

# XXX
# Flag on weight as qty (which underwent a change) will populate weight
#
tldata <- tldata %>%
  setFlag3(weight > 0, type = 'method', flag = 'i', variable = 'weight') %>%
  setFlag3(cond_q,     type = 'method', flag = 'i', variable = 'weight')

##' # Combine Trade Data Sources

######### Value from USD to thousands of USD

##+ es_convcur

##' 1. Convert currency of monetary values from EUR to USD using the
##' `EURconversionUSD` table (required only for ES).

eur_usd <- as.numeric(EURconversionUSD[eusd_year == year,]$eusd_exchangerate)

esdata$value <- esdata$value * eur_usd

esdata <- esdata %>%
    setFlag3(value > 0, type = 'method', flag = 'i', variable = 'value')


##' 1. Convert data in thousands of dollars.

if (dollars) {
  esdata <- esdata %>%
    dplyr::mutate(value = value * 1000) %>%
    setFlag3(value > 0, type = 'method', flag = 'i', variable = 'value')
} else { ## This means it is in k$
  tldata <- tldata %>%
    dplyr::mutate(value = value / 1000) %>%
    setFlag3(value > 0, type = 'method', flag = 'i', variable = 'value')
}

##+ tl_aggregate

tldata_mid = tldata

  ###' 1. Assign 'weight' flags to 'qty' flags in TL XXX.
  #
  # NO: this isn't needed as below qty = weight and it has already its own flag
  #
  #tldata <- tldata %>%
  #  dplyr::mutate_each_(funs(swapFlags(., swap='\\1\\2\\2'), !is.na(weight)),
  #               ~starts_with('flag_'))

esdata <- esdata %>%
  dplyr::mutate(qtycpc = ifelse(finalunit == "mt", weight, qty))

# Assign `qty` flags to `weight` flags in ES but
# only when `finalunit` is different from "mt".


esdata <- esdata %>%
  dplyr::mutate_each_(funs(swapFlags(., swap='\\1\\3\\3', finalunit != "mt")),
               ~starts_with('flag_'))


##' 1. Combine Tariff line and Eurostat data sources in a single data set:
##'     - TL: assign `weight` to `qty`.
##'     - ES: assign `weight` to `qty` if `finalunit` is "mt", else keep `qty`.

##+ combine_es_tl
flog.trace("[%s] Combine TL and ES data sets", PID, name = "dev")
tradedata <- bind_rows(
  tldata %>%
    dplyr::select(year, reporter, partner, flow, cpc, fcl, finalunit, hs,
            value, weight, qty = qtycpc,
            convspec_head, starts_with('flag_'), wco),
  esdata %>%
    dplyr::mutate(convspec_head = NA_real_, wco = NA_character_) %>%
    dplyr::select(year, reporter, partner, flow, cpc, fcl, finalunit, hs,
            value, weight, qty = qtycpc,
            convspec_head, starts_with('flag_'), wco)
)

# XXX this is fine, but probably the name of the function should be changed
tradedata <- tradedata %>%
  dplyr::mutate_each_(funs(swapFlags(., swap='\\1\\2')), ~starts_with('flag_'))

### Check for double counting of HS codes
#hs_many_lengths = getHsManyLengths(tradedata)
#rprt_writetable(hs_many_lengths, subdir = 'details')

flog.trace("[%s] Outlier detection and imputation", PID, name = "dev")
##+ calculate_median_uv

tradedata <- tradedata %>%
  dplyr::mutate(
    no_quant = finalunit != '$ value only' & (near(qty, 0) | is.na(qty)),
    no_value = near(value, 0) | is.na(value)
  )

##' 1. Unit values are calculated for each observation at the HS level as ratio
##' of monetary value over quantity: $uv = value / qty$.

tradedata <- dplyr::mutate_(tradedata,
                     uv = ~ifelse(no_quant | no_value, NA, value / qty))

## Round UV in order to avoid floating point number problems (see issue #54)
tradedata$uv <- round(tradedata$uv, 10)

##+ boxplot_uv

if (detect_outliers) {
  tradedata <- detectOutliers(tradedata = tradedata,
                              method = "boxplot",
                              parameters = list(out_coef = out_coef))
} else {
  tradedata$outlier <- FALSE
}

##' # Imputation

##+ impute_qty_uv

##' 1. Imputation of missing quantities by applying the method presented
##' in the *Missing Quantities Imputation* subsection of the *faoswsTrade:
##' `complete_tf_cpc` and `total_trade_CPC` modules* document
##' (*Standardization, editing and outlier detection* section). The
##' `flagTrade` variable is given a value of 1 if an imputation was performed.

## These flags are also assigned to monetary values. This may need to be
## revised (monetary values are not supposed to be modified).

tradedata <- computeMedianUnitValue(tradedata = tradedata)

tradedata <- doImputation(tradedata = tradedata)

flog.trace("[%s] Flag stuff", PID, name = "dev")
# XXX using flagTrade for the moment, but should go away
# (Team BC: quantities below 1 tonne do not get imputed flag)
tradedata <- tradedata %>%
    setFlag2(flagTrade > 0 & qty > 1,
             type = 'status', flag = 'I', var = 'quantity') %>%
    setFlag2(flagTrade > 0 & qty > 1,
             type = 'method', flag = 'e', var = 'quantity')

##' # Additional operations

##' 1. Separate flags.

###### TODO (Christian) Rethink/refactor
# separate flag_method and flag_status into 2 variables each one: _v and _q
flag_vars <- colnames(tradedata)[grep('flag_', colnames(tradedata))]
for (var in flag_vars) {
  tradedata <- separate_(tradedata, var, 1:2,
                         into = c('x', paste0(var, '_', c('v', 'q'))),
                         convert = TRUE) %>%
               dplyr::select(-x)
}

tradedata_flags <- tradedata %>%
  group_by_(~year, ~reporter, ~partner, ~flow, ~cpc, ~fcl) %>%
  dplyr::summarise_each_(funs(sum(.)), vars = ~starts_with('flag_')) %>%
  ungroup() %>%
  dplyr::mutate_each_(funs(as.integer(. > 0)), vars = ~starts_with('flag_'))

##' 1. Aggregate values, quantities, and flags by CPC codes.

# Aggregation by CPC/FCL
flog.trace("[%s] Aggregation by CPC", PID, name = "dev")
tradedata <- tradedata %>%
  dplyr::mutate_(ncpcfcl = 1) %>%
  group_by_(~year, ~reporter, ~partner, ~flow, ~cpc, ~fcl, ~finalunit) %>%
  dplyr::summarise_each_(
    funs(sum(., na.rm = TRUE)),
    vars = c("value", "weight", "qty", "flagTrade", "ncpcfcl")
  ) %>%
  ungroup()

# XXX not all weights were estimated, so after aggregation they are zero
tradedata <-
  tradedata %>%
  dplyr::mutate(weight = ifelse(near(weight, 0), NA, weight))


flog.trace("[%s] Flags again", PID, name = "dev")
tradedata <- left_join(tradedata,
                       tradedata_flags,
                       by = c('year', 'reporter', 'partner', 'flow', 'cpc', 'fcl'))

###### TODO (Christian) Rethink/refactor
# unite _v and _q into one variable
flag_vars <- sort(unique(sub('_[vq]$', '', colnames(tradedata)[grep('flag_', colnames(tradedata))])))
for (var in flag_vars) {
  var_v <- paste0(var, '_v')
  var_q <- paste0(var, '_q')

  tradedata[[var]] <- 100 + (tradedata[[var_v]]>0)*10 + (tradedata[[var_q]]>0)*1
}
tradedata <- tradedata[-grep('^flag_.*[vq]$', colnames(tradedata))]

tradedata <- tradedata %>%
  setFlag2(ncpcfcl > 1,  type = 'method', flag = 's', variable = 'all')

##' 1. Map FAO area codes to M49. Countries with FAOSTAT code 252
##' ("Unspecified") are converted to M49 code 896 ("Other nei").

# Converting back to M49 for the system
flog.trace("[%s] Convert FAO area codes to M49", PID, name = "dev")
tradedata <- tradedata %>%
  dplyr::mutate_(
    reporterM49 = ~fs2m49(as.character(reporter)),
    partnerM49  = ~fs2m49(as.character(partner))
  ) %>%
  # XXX issue 34
  dplyr::mutate(partnerM49 = ifelse(partner == 252, '896', partnerM49))

# Report of countries mapping to NA in M49
countries_not_mapping_M49 <- bind_rows(
  tradedata %>% select_(fc = ~reporter, m49 = ~reporterM49),
  tradedata %>% select_(fc = ~partner,  m49 = ~partnerM49)) %>%
  distinct_() %>%
  filter_(~is.na(m49)) %>%
  select_(~fc) %>%
  unlist()

##+ mirror_estimation

##' # Mirror Trade Estimation

##' 1. Create a table with the list of reporters and partners
##' combined as areas and count the number of flows that the
##' areas declare as reporting countries. The partners that
##' never show up as reporters or the reporters that do not
##' report a flow will have a number of flows equal to zero
##' and will be mirrored.
flog.trace("[%s] Mirroring", PID, name = "dev")

to_mirror <- flowsToMirror(tradedata) %>%
  dplyr::filter(area != 252)

##' 1. Swap the reporter and partner dimensions: the value previously appearing
##' as reporter country code becomes the partner country code (and vice versa).

##' 1. Invert the flow direction: an import becomes an export (and vice versa).

##' 1. Calculate monetary mirror value by adding (removing) a 12% mark-up on
##' imports (exports) to account for the difference between CIF and FOB prices.

## Mirroring for non reporting countries
tradedata <- mirrorNonReporters(tradedata, mirror = to_mirror)

# Add an auxiliary variable "mirrored" that will be removed later
tradedata <- tradedata %>%
  left_join(
    to_mirror %>% dplyr::mutate(mirrored = 1L),
    by = c('reporter' = 'area', 'flow')
  )

flog.trace("[%s] Flags to mirrored flows", PID, name = "dev")

tradedata <- tradedata %>%
  setFlag2(!is.na(mirrored), type = 'status', flag = 'T', var = 'all') %>%
  setFlag2(!is.na(mirrored), type = 'method', flag = 'i', var = 'value') %>%
  setFlag2(!is.na(mirrored), type = 'method', flag = 'c', var = 'quantity') %>%
  dplyr::select(-mirrored)

##' # Flag aggregation

##' Flags are aggregated as mentioned in the *Flags* section in
##' the main documentation or, more in depth, in the "Flag Management
##' in the Trade module" document.

################################################
# TODO Rethink/refactor: clean flags for finalunit != "$ value only"
################################################

##+ completed_trade_flow

###### TODO (Christian) Rethink/refactor
# separate flag_method and flag_status into 2 variables each one: _v and _q
flag_vars <- colnames(tradedata)[grep('flag_', colnames(tradedata))]
for (var in flag_vars) {
  tradedata <- separate_(tradedata, var, 1:2,
                         into = c('x', paste0(var, '_', c('v', 'q'))),
                         convert = TRUE) %>%
               dplyr::select(-x)
}

##' # Output for SWS

##' 1. Filter observations with CPC code `02196` (bees).

##' 1. Filter observations with missing CPC codes.

##' 1. Rename dimensions to comply with SWS standard,
##' e.g., `geographicAreaM49Reporter`.

##' 1. Calculate unit value (US$ per quantity unit) at CPC
##' level if the quantity is larger than zero.

# Modified in order to have X in the table
flagWeightTable_status <- frame_data(
  ~flagObservationStatus, ~flagObservationWeights,
  'X',                   1.00,
  '',                    0.99,
  'T',                   0.80,
  'E',                   0.75,
  'I',                   0.50,
  'M',                   0.00
)

# There is no native "method" table
flagWeightTable_method <- frame_data(
  ~flagObservationStatus, ~flagObservationWeights,
  'h',                   1.00,
  'i',                   0.80,
  'e',                   0.60,
  'c',                   0.40,
  's',                   0.20
)

# XXX This will need a refactoring
flog.trace("[%s] Cycle on status and method flags", PID, name = "dev")
for (i in c('status', 'method')) {
  for (j in c('v', 'q')) {

    dummies <-
      tradedata %>%
      dplyr::select(matches(paste0('flag_', i, '_._', j))) %>%
      dplyr::mutate_all(funs(ifelse(equals(., 0), NA, .)))

    flags <- sub('.*_(.)_.$', '\\1', colnames(dummies))

    flagWeightTable <-
      switch(i, status = flagWeightTable_status, method = flagWeightTable_method)

    found_flags <- flagWeightTable[match(flags, flagWeightTable$flagObservationStatus),]

    var <- paste0('flag', toupper(i), '_', j)

    final_flags <- suppressWarnings(apply(t(t(as.matrix(dummies)) * (found_flags$flagObservationWeights)), 1, min, na.rm = TRUE))

    final_flags[is.infinite(final_flags)] <- NA

    final_flags <- found_flags$flagObservationStatus[match(final_flags, found_flags$flagObservationWeights)]

    tradedata[[var]] <- final_flags
  }
}

flog.trace("[%s] Complete trade flow CPC", PID, name = "dev")
complete_trade_flow_cpc <- tradedata %>%
  filter_(~cpc != '02196') %>% ## Subsetting out bees (FCL = 1181)
  filter_(~!(is.na(cpc))) %>%
  transmute_(geographicAreaM49Reporter = ~reporterM49,
             geographicAreaM49Partner  = ~partnerM49,
             flow                      = ~flow,
             timePointYears            = ~year,
             measuredItemCPC           = ~cpc,
             value                     = ~value,
             weight                    = ~weight,
             qty                       = ~qty,
             unit                      = ~finalunit,
             flagObservationStatus_v   = ~flagSTATUS_v,
             flagObservationStatus_q   = ~flagSTATUS_q,
             flagMethod_v              = ~flagMETHOD_v,
             flagMethod_q              = ~flagMETHOD_q) %>%
  ## unit of monetary values is "1000 $"
  dplyr::mutate(uv = ifelse(qty > 0, value * 1000 / qty, NA))

##' 1. Keep officially reported weight in kilograms for livestock.
##' Besides of quantities in "heads" or "1000 heads" if a country
##' reported also the weight, it will be kept and saved to SWS.

# Keep weight for livestock
complete_trade_flow_cpc_live <-
  complete_trade_flow_cpc %>%
  filter(unit %in% c('heads', '1000 heads')) %>%
  # XXX for now, no flags
  dplyr::select(-starts_with('flag')) %>%
  dplyr::mutate(flagObservationStatus = '', flagMethod = '') %>%
  # we need here just weight
  dplyr::mutate(measuredElementTrade = ifelse(flow == 1, '5610', '5910')) %>%
  dplyr::select(-value, -qty, -uv, -unit, -flow) %>%
  rename(Value = weight)

# remove weight as not needed anymore
complete_trade_flow_cpc <-
  complete_trade_flow_cpc %>%
  dplyr::select(-weight)

##' 1. Use corrections set by analysts during the validation process.

corrections_table <- corrections_table_all %>%
  dplyr::rename(correction_year = year) %>%
  dplyr::filter(correction_year == year)

corrections_exist <- nrow(corrections_table) > 0

if (corrections_exist) {
  flog.trace("[%s] Corrections exist", PID, name = "dev")

  corrections_table <- corrections_table %>%
    dplyr::filter(correction_level == 'CPC') %>%
    dplyr::select(-correction_year, -correction_level, -correction_hs) %>%
    # Some of these cases were found, but are probably mistakes: should inform
    dplyr::filter(!is.na(correction_input) | !near(correction_input, 0)) %>%
    # XXX actually, flow should be integer in complete_trade_flow_cpc
    dplyr::mutate(flow = as.numeric(flow)) %>%
    # XXX Remove duplicate corrections
    group_by(reporter, partner, item, flow, data_type) %>%
    dplyr::arrange(dplyr::desc(date_correction)) %>%
    dplyr::slice(1) %>%
    ungroup()

  corrections_metadata <- apply(select(corrections_table, name_analyst, data_original, correction_type:date_validation),
                                1, function(x) paste(names(x), ifelse(x == '', NA, x), collapse = '; ', sep = ': '))

  corrections_table <- corrections_table %>%
    dplyr::select(-(correction_note:date_validation)) %>%
    dplyr::mutate(correction_metadata = gsub('  *', ' ', corrections_metadata))

  flog.trace("[%s] Apply corrections to reporter", PID, name = "dev")

  complete_corrected <- useValidationCorrections(complete_trade_flow_cpc,
                                                 corrections_table)

  complete_trade_flow_cpc_mirror <- complete_trade_flow_cpc %>%
    dplyr::mutate(is_mirror = (flagObservationStatus_v %in% 'T' | flagObservationStatus_q %in% 'T')) %>%
    dplyr::filter(is_mirror) %>%
    dplyr::select(-is_mirror)

  complete_with_corrections_mirror <- complete_corrected$corrected %>%
    dplyr::select(
      geographicAreaM49Reporter = geographicAreaM49Partner,
      geographicAreaM49Partner  = geographicAreaM49Reporter,
      flow,
      measuredItemCPC
    ) %>%
    dplyr::mutate(flow = recode(flow, '2' = 1, '1' = 2), to_correct = TRUE)

  complete_mirror_to_correct <- complete_trade_flow_cpc_mirror %>%
    left_join(
      complete_with_corrections_mirror,
      by = c(
        'geographicAreaM49Reporter',
        'geographicAreaM49Partner',
        'flow',
        'measuredItemCPC'
      )
    ) %>%
    dplyr::filter(to_correct) %>%
    dplyr::select(-to_correct)

  corrections_table_mirror <- corrections_table %>%
    dplyr::rename(reporter = partner, partner = reporter) %>%
    dplyr::mutate(flow = recode(flow, '2' = 1, '1' = 2)) %>%
    dplyr::mutate(correction_input = ifelse(data_type == 'value', ifelse(flow == 1, correction_input * 1.12, correction_input / 1.12), correction_input))

  flog.trace("[%s] Apply corrections to partner (if mirrored)", PID, name = "dev")

  complete_mirror_corrected <- useValidationCorrections(complete_mirror_to_correct,
                                                        corrections_table_mirror)

  complete_all_corrected <- bind_rows(complete_corrected$corrected,
                                      complete_mirror_corrected$corrected)

  complete_uncorrected <- complete_trade_flow_cpc %>%
    anti_join(
      complete_all_corrected,
      by = c('geographicAreaM49Reporter', 'geographicAreaM49Partner',
             'flow', 'measuredItemCPC')
    )

  complete_trade_flow_cpc <- bind_rows(complete_uncorrected,
                                       complete_all_corrected)

  if (nrow(complete_corrected$to_drop) > 0) {
    flog.trace("[%s] Some corrections were not applied", PID, name = "dev")

    warning('Some corrections were not applied. See reports.')
    corrections_unapplied <- complete_corrected$to_drop %>%
      dplyr::mutate(year = year) %>%
      dplyr::select(-correction_metadata) %>%
      left_join(
        corrections_table_all,
        by = c('year', 'reporter', 'partner', 'item',
               'flow', 'data_original',
               'data_type', 'correction_input',
               'correction_type')
      ) %>%
      dplyr::select(year, everything()) %>%
      as.data.frame()

    rprt_writetable(corrections_unapplied, subdir = 'preproc')

    # File to check to be loaded in the validation tool: it
    # will contain also the new figures generated by the module
    corrections_unapplied_validation <-
      left_join(
        corrections_unapplied,
        complete_trade_flow_cpc %>%
          dplyr::select(
            geographicAreaM49Reporter,
            geographicAreaM49Partner,
            flow,
            timePointYears,
            measuredItemCPC,
            value,
            qty
          ),
        by = c(
          'flow',
          'reporter' = 'geographicAreaM49Reporter',
          'partner'  = 'geographicAreaM49Partner',
          'item'     = 'measuredItemCPC',
          'year'     = 'timePointYears'
        )
      ) %>%
      dplyr::mutate(data_new = ifelse(data_type == 'qty', qty, value)) %>%
      dplyr::select(year, reporter, partner, item, flow,
                    data_new, everything(), -value, -qty)


    # XXX add dir.create if it doesn't exist
    saveRDS(
      corrections_unapplied_validation,
      file = file.path(corrections_dir, 'unapplied', paste0(year, '.rds'))
    )

    # Original corrections with the unapplied ones removed
    corrections_table_all_rm_unapplied <-
      anti_join(
        corrections_table_all,
        corrections_unapplied,
        by = c('reporter', 'partner', 'year', 'item',
               'flow', 'data_type', 'correction_level')
        )

    # Save the corrections again for reporters that had unapplied corrections
    # XXX add check for error in writing
    invisible(
      sapply(
        unique(corrections_unapplied$reporter),
        function(x) {
          saveRDS(
            dplyr::filter(corrections_table_all_rm_unapplied, reporter == x),
            file = file.path(corrections_dir, x, 'corrections_table.rds')
          )
        },
        USE.NAMES = FALSE
      )
    )

  }

} else {
  flog.trace("[%s] Corrections do not exist", PID, name = "dev")

  complete_trade_flow_cpc <- complete_trade_flow_cpc %>%
    dplyr::mutate(
      correction_metadata_qty   = NA_character_,
      correction_metadata_value = NA_character_
    )
}

##' 1. Transform dataset separating monetary values, quantities and unit values
##' in different rows.

##' 1. Convert monetary values, quantities and unit values to corresponding SWS
##' element codes. For example, a quantity import measured in metric tons is
##' assigned `5610`.

##+ convert_element

quantityElements <- c("5608", "5609", "5610", "5908", "5909", "5910")
uvElements       <- c("5638", "5639", "5630", "5938", "5939", "5930")

complete_trade_flow_cpc <- complete_trade_flow_cpc %>%
  tidyr::gather(
    measuredElementTrade, Value, -geographicAreaM49Reporter,
    -geographicAreaM49Partner, -measuredItemCPC, -timePointYears,
    -flagObservationStatus_v, -flagObservationStatus_q,
    -flagMethod_v, -flagMethod_q, -unit, -flow,
    -correction_metadata_qty, -correction_metadata_value
  ) %>%
  rowwise() %>%
  dplyr::mutate_(
    measuredElementTrade =
      ~convertMeasuredElementTrade(
        measuredElementTrade,
        unit,
        flow
      )
  ) %>%
  ungroup() %>%
  filter_(~measuredElementTrade != "999") %>%
  dplyr::mutate(
    correction_metadata_uv =
      ifelse(
        !is.na(correction_metadata_qty),
        ifelse(
          !is.na(correction_metadata_value),
          paste('QTY:', correction_metadata_qty, '| VALUE:', correction_metadata_value),
          correction_metadata_qty
        ),
        correction_metadata_value
      ),
    correction_metadata =
      ifelse(
        measuredElementTrade %in% quantityElements,
        correction_metadata_qty,
        ifelse(
          measuredElementTrade %in% uvElements,
          correction_metadata_uv,
          correction_metadata_value
        )
      )
  ) %>%
  select_(
    ~-flow, ~-unit, ~-correction_metadata_qty,
    ~-correction_metadata_value, ~-correction_metadata_uv
  )

if (corrections_exist) {
  flog.trace("[%s] Generating metadata data.table", PID, name = "dev")

##' 1. Generate metadata for corrections.

  metad <- complete_trade_flow_cpc %>%
    dplyr::filter(!is.na(correction_metadata)) %>%
    dplyr::select(
      geographicAreaM49Reporter,
      geographicAreaM49Partner,
      measuredElementTrade,
      measuredItemCPC,
      timePointYears,
      correction_metadata
    ) %>%
    dplyr::mutate(
      Metadata          = "GENERAL",
      Metadata_Element  = "COMMENT",
      Metadata_Language = "en",
      Metadata_Value    = correction_metadata
    ) #%>%
    ### NOTE: metadata can be splitted as shown below, though there is
    ### still some work to do on how to store metadata of unit values
    #separate(
    #  correction_metadata, # Or Metadata_Value, if computed above
    #  into = c(
    #    'name_analyst',
    #    'data_original',
    #    'correction_type',
    #    'correction_note',
    #    'note_analyst',
    #    'note_supervisor',
    #    'name_supervisor',
    #    'date_correction',
    #    'date_validation'
    #  ),
    #  sep = ' *; *'
    #) %>%
    #gather(
    #  key,
    #  value,
    #  name_analyst,
    #  data_original,
    #  correction_type,
    #  correction_note,
    #  note_analyst,
    #  note_supervisor,
    #  name_supervisor,
    #  date_correction,
    #  date_validation
    #) %>%
    #select(-key) %>%
    #dplyr::rename(Metadata_Value = value)

  # Required to be a data.table
  metad <- dplyr::select(metad, -correction_metadata) %>%
    as.data.table()
}

complete_trade_flow_cpc <- complete_trade_flow_cpc %>%
  dplyr::select(-correction_metadata) %>%
  dplyr::mutate(
    flagObservationStatus = ifelse(measuredElementTrade %in% quantityElements,
                                   flagObservationStatus_q,
                                   flagObservationStatus_v),
    flagMethod            = ifelse(measuredElementTrade %in% quantityElements,
                                   flagMethod_q,
                                   flagMethod_v)
  ) %>%
  # The Status flag will be equal to the weakest flag between
  # the numerator and the denominator, in this case the denominator.
  dplyr::mutate(
    flagObservationStatus = ifelse(measuredElementTrade %in% uvElements,
                                   flagObservationStatus_q,
                                   flagObservationStatus),
    flagMethod            = ifelse(measuredElementTrade %in% uvElements,
                                   'i',
                                   flagMethod)
  ) %>%
  dplyr::select(
    -flagObservationStatus_v, -flagObservationStatus_q,
    -flagMethod_v, -flagMethod_q
  )

# Adding weights for livestock
complete_trade_flow_cpc <-
  bind_rows(
    complete_trade_flow_cpc,
    complete_trade_flow_cpc_live
  )


complete_trade_flow_cpc <- data.table::as.data.table(complete_trade_flow_cpc)

data.table::setcolorder(complete_trade_flow_cpc,
                        c("geographicAreaM49Reporter",
                          "geographicAreaM49Partner",
                          "measuredElementTrade",
                          "measuredItemCPC",
                          "timePointYears",
                          "Value",
                          "flagObservationStatus",
                          "flagMethod"))

# XXX Temporary workaround: some NAs are given flags and given
# that NAs cannot have flags the system refuses to save them.
# These NAs are unit values computed on a zero quantity. Setting
# Value to zero.
complete_trade_flow_cpc[is.na(Value), Value := 0]

# "official" status flag should be <BLANK> instead of X (this was a choice
# made after X was chosen as official flag). Thus, change X to <BLANK>.
complete_trade_flow_cpc[flagObservationStatus == 'X', flagObservationStatus := '']


##' 1. Removed "protected" data from the module's output.

##' 1. Remove transactions saved on SWS that are not generated
##' by the module.

if (remove_nonexistent_transactions) {
  flog.trace("[%s] Remove non-existent transactions (RNET)", PID, name = "dev")

  GetCodeList2 <- function(dimension = NA) {
    GetCodeList(
      domain    = 'trade',
      dataset   = 'completed_tf_cpc_m49',
      dimension = dimension
    )
  }

  Keys <- list(reporters = GetCodeList2(dimension = 'geographicAreaM49Reporter')[type == 'country', code],
               partners  = GetCodeList2(dimension = 'geographicAreaM49Partner')[type == 'country', code],
               items     = GetCodeList2(dimension = 'measuredItemCPC')[, code],
               elements  = GetCodeList2(dimension = 'measuredElementTrade')[, code],
               years     = as.character(year))

  # TODO: use error handling
  key <- DatasetKey(domain     = 'trade',
                    dataset    = 'completed_tf_cpc_m49',
                    dimensions = list(
                      Dimension(name = 'geographicAreaM49Reporter', keys = Keys[['reporters']]),
                      Dimension(name = 'geographicAreaM49Partner',  keys = Keys[['partners']]),
                      Dimension(name = 'measuredItemCPC',           keys = Keys[['items']]),
                      Dimension(name = 'measuredElementTrade',      keys = Keys[['elements']]),
                      Dimension(name = 'timePointYears',            keys = Keys[['years']])))

  flog.trace("[%s] RNET: Download existent SWS dataset", PID, name = "dev")

  existing_data <- GetData(key = key, omitna = TRUE)

  flog.trace("[%s] Keep protected data", PID, name = "dev")

  # Some flags are "protected", i.e., data with these flags
  # should not be overwritten/removed
  protected_flags <-
    flagValidTable[Protected == TRUE &
                   !(flagObservationStatus == 'T' &  flagMethod == 'c') &
                   !(flagObservationStatus == ''  &  flagMethod == 'c') &
                   !(flagObservationStatus == ''  &  flagMethod == 'h'),
                   paste(flagObservationStatus, flagMethod)]

  # Data that should be left untouched
  protected_data <-
    existing_data[paste(flagObservationStatus, flagMethod) %in% protected_flags,]

  # XXX If timePointYears will eventually be used they need to
  # have the same class in existing_data and complete_trade_flow_cpc

  # Remove from saved data
  existing_data <-
    existing_data[!protected_data,
                  on = c('geographicAreaM49Reporter',
                         'geographicAreaM49Partner',
                         'measuredElementTrade',
                         'measuredItemCPC')]

  # Remove from new data
  complete_trade_flow_cpc <-
    complete_trade_flow_cpc[!protected_data,
                            on = c('geographicAreaM49Reporter',
                                   'geographicAreaM49Partner',
                                   'measuredElementTrade',
                                   'measuredItemCPC')]


  # Difference between what was saved and what the module produced:
  # whatever is not produced in the run should be set to NA. See #164
  # (No need of year as key as all data refer to the same year)
  data_diff <-
    existing_data[!complete_trade_flow_cpc,
                  on = c('geographicAreaM49Reporter',
                         'geographicAreaM49Partner',
                         'measuredElementTrade',
                         'measuredItemCPC')]

  if (nrow(data_diff) > 0) {
    flog.trace("[%s] RNET: Non-existent transactions set to NA", PID, name = "dev")

    data_diff[,`:=`(Value                 = NA_real_,
                    flagObservationStatus = NA_character_,
                    flagMethod            = NA_character_)]

    complete_trade_flow_cpc <- rbind(complete_trade_flow_cpc, data_diff)
  } else {
    flog.trace("[%s] RNET: There are no non-existent transactions", PID, name = "dev")
  }
}

##' # Save data

##' Finally, data is saved in the `completed_tf_cpc_m49` dataset of
##' the `trade` domain.

flog.trace("[%s] Writing data to session/database", PID, name = "dev")

if (corrections_exist) {
  stats <- SaveData("trade",
                    "completed_tf_cpc_m49",
                    complete_trade_flow_cpc,
                    metadata    = metad,
                    waitTimeout = 10800)
} else {
  stats <- SaveData("trade",
                    "completed_tf_cpc_m49",
                    complete_trade_flow_cpc,
                    waitTimeout = 10800)
}

if (!CheckDebug()) {
  updateInfoTable(year = year, table = 'complete_tf_runs_info',
                  mode = 'save', results = stats)
}

## remove value only

flog.trace("[%s] Session/database write completed!", PID, name = "dev")

flog.info(
  "Module completed in %1.2f minutes.
  Values inserted: %s
  appended: %s
  ignored: %s
  discarded: %s",
    difftime(Sys.time(), startTime, units = "min"),
    stats[["inserted"]],
    stats[["appended"]],
    stats[["ignored"]],
    stats[["discarded"]], name = "dev"
  )

# Restore changed options
options(old_options)

sprintf(
  "Module completed in %1.2f minutes.
  Values inserted: %s
  appended: %s
  ignored: %s
  discarded: %s",
  difftime(Sys.time(), startTime, units = "min"),
  stats[["inserted"]],
  stats[["appended"]],
  stats[["ignored"]],
  stats[["discarded"]]
)

